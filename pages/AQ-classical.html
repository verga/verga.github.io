<!DOCTYPE html>
<html lang="en">

  <head>
    <!-- Required meta tags always come first -->
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <title>Classical information | Random physics
</title>
    <link rel="canonical" href="/pages/AQ-classical.html">

    <link rel="stylesheet" href="/theme/css/bootstrapr.min.css">
    <link rel="stylesheet" href="/theme/css/font-awesome.min.css">
    <link rel="stylesheet" href="/theme/css/pygments/autumn.min.css">
    <link rel="stylesheet" href="/theme/css/style.css">

    <link rel="icon" type="image/png" href="/extras/rphys.png" sizes="64x64">

<meta name="description" content="Information is physical (Landauer), Shannon entropy">

  </head>

  <body>
    <header class="header">
      <div class="container">
        <div class="row">
          <div class="col-sm-12">
            <h1 class="title"><a href="/">Random physics</a></h1>
            <p class="text-muted">Alberto Verga, research notebook</p>
              <ul class="list-inline">
                  <li class="list-inline-item"><a href="/">Blog</a></li>
                      <li class="list-inline-item text-muted">|</li>
                      <li class="list-inline-item"><a href="/pages/about.html">About</a></li>
                      <li class="list-inline-item"><a href="/pages/lectures.html">Lectures</a></li>
              </ul>
          </div>
        </div>
      </div>
    </header>

    <div class="main">
      <div class="container">

<article class="article">
  <div class="content">
    <p><span class="math">\(\newcommand{\I}{\mathrm{i}} 
\newcommand{\E}{\mathrm{e}} 
\newcommand{\D}{\mathop{}\!\mathrm{d}} 
\DeclareMathOperator{\Tr}{Tr}
\newcommand{\bra}[1]{\langle{#1}|}
\newcommand{\ket}[1]{|{#1}\rangle}
\newcommand{\braket}[1]{\langle{#1}\rangle}
\newcommand{\bbraket}[1]{\langle\!\langle{#1}\rangle\!\rangle}&nbsp;\newcommand{\bm}{\boldsymbol}\)</span></p>
<blockquote>
<p><a href="/pages/AQ-index.html">Lectures</a> on advanced quantum&nbsp;mechanics</p>
</blockquote>
<h1>Information is&nbsp;physical</h1>
<p>A discussion about Maxwell demon, the Szilard model, the Landauer principle, and the Bennett<sup id="fnref:Bennett"><a class="footnote-ref" href="#fn:Bennett">1</a></sup> solution of the paradox can be found in the <a href="/L3-demon.html">Leçon de physique</a>. For completeness I reproduce here the main&nbsp;point.</p>
<p>Maxwell devised an &#8220;intelligent being&#8221; that can distribute the molecules to the left or to the right of a vessel with two separated compartments, according to their velocities: to the left the faster ones and to the right the slower ones; hence obtaining from an initially equilibrium system a difference of temperature that can be used to push from the left to the right a piston. This is in contradiction with the second principle. Szilard simplified the problem to a system composed by a unique molecule and the demon a simple logical register that can store one bit, as in the&nbsp;figure:</p>
<blockquote>
<p><img src="/images/PS-szilard-2.svg" alt="Szilard engine plus demon" style="width: 320px;"/></p>
<p>In the initial state (a) the particle is somewhere inside the box and the demon register is empty <span class="math">\((0,0)\)</span>, in the second panel (b) the demon identifies the position of the particle filling its left register <span class="math">\((0,1)\)</span> (the three possible states of the register are empty, left, or right). It then applies a logical operation to put the piston on the correct side to gain work from the gas (c) <em>or</em> (c&#8217;). Finally (d), the particle recovers its initial state. Note however that the demon register is filled (one bit of information is stored), meaning the (d) is not equivalent to (a). Note the branching from (b) to (c),&nbsp;(c&#8217;).</p>
</blockquote>
<p>One important point of the Bennett argument to solve the paradox is based on the fact that logical operations can be donne reversibly (the step (c) in the figure). We know that logical circuits are build from elementary logical operators (gates in an electronic device). For instance the <em>not</em> gate takes an input bit and outputs a single bit implementing the logical&nbsp;table:</p>
<blockquote>
<table style="width:200px;">
<caption><span class="caps">NOT</span> gate</caption>
<tr>
<th>in</th>
<th></th>
<th>out</th>
</tr>
<tr>
<th>T</th>
<th>\(\rightarrow\)</th>
<th>F</th>
</tr>
<tr>
<th>F</th>
<th>\(\rightarrow\)</th>
<th>T</th>
</tr>
</table>
</blockquote>

<p>where T stands for true and F for false; equivalently we may&nbsp;write,
</p>
<div class="math">\begin{align*}
  0 &amp;\rightarrow 1\\
  1 &amp;\rightarrow 0
\end{align*}</div>
<p>
and the <em>nand</em> gate (&#8220;not&nbsp;and&#8221;):</p>
<blockquote>
<table style="width:200px;">
<caption><span class="caps">NAND</span> gate</caption>
<tr>
<th>in</th>
<th>in</th>
<th></th>
<th>out</th>
</tr>
<tr>
<th>T</th>
<th>T</th>
<th>\(\rightarrow\)</th>
<th>F</th>
</tr>
<tr>
<th>T</th>
<th>F</th>
<th>\(\rightarrow\)</th>
<th>T</th>
</tr>
<tr>
<th>F</th>
<th>T</th>
<th>\(\rightarrow\)</th>
<th>T</th>
</tr>
<tr>
<th>F</th>
<th>F</th>
<th>\(\rightarrow\)</th>
<th>T</th>
</tr>
</table>
</blockquote>

<p>which takes two input bits <span class="math">\(x, y \in \{0,1\} = \{\mathrm{F}, \mathrm{T}\}\)</span> and outputs&nbsp;one:
</p>
<div class="math">$$(x,y) \rightarrow 1 \oplus xy$$</div>
<p>
the output bit is the addition modulo 2 of 1 and the product <span class="math">\(xy\)</span>. (Using the same operation the not gate is <span class="math">\(x \rightarrow 1 \oplus x\)</span>.)</p>
<p>We see that while the not operation is reversible (you can infer the input form the output), the nand gate is irreversible: information of the input is lost under this operation. The Landauer principle states that erasing a bit increases the entropy by an amount <span class="math">\(k_B \ln 2\)</span> (in joules<span class="math">\(/\)</span>kelvin). Therefore, if the Maxwell demon uses a logical circuit to decide if a given molecule must go to the left or to the right chambers, some dissipation would arise because of the irreversibility of the logical operation. However, it is not so difficult to show that a complete set of gates, a set which allows build any circuit, can be done reversibly. As a consequence, irreversibility will only appear in the last step of the Szilard cycle, when the demon register must be <em>erased</em> to recover its initial empty state. Under erasure entropy&nbsp;increases:
</p>
<div class="math">$$\Delta S = k_\mathrm{B} \ln 2 \quad (\text{demon}) \,,$$</div>
<p>
which is <em>Landauer principle</em>.</p>
<p>One may argue that the necessity of erasing comes from the necessity to merge the two branches created after (b), (c) and (c&#8217;); and, physically, the necessity of branching in (b) comes from the random character of the particle&nbsp;motion.</p>
<p>In fact a reversible version of the nand gate was found by Toffoli gate; the main idea is to add two input bits in order to keep track of the initial&nbsp;state:
</p>
<div class="math">$$(x,y,z) \rightarrow (x,y,z \oplus xy)$$</div>
<p>
when the third bit is 1 we recover the nand result. Note that the output is also a set of 3 bits, to ensure that we can recover the initial input. The Toffoli gate can be represented by a&nbsp;matrix:
</p>
<div class="math">$$\mathrm{toffoli} = \begin{pmatrix} 
  1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
  0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
  0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
  0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
  0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
  0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
  0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
  0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \end{pmatrix}$$</div>
<p>
that can be applied to the canonical base corresponding the 8 input bits: <span class="math">\(000, 001,\ldots,111\)</span>; for&nbsp;example:
</p>
<div class="math">$$010 \rightarrow \begin{pmatrix} 0 \\ 0 \\ 1 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \end{pmatrix}\,.$$</div>
<p>
You may find its inverse <strong style="color:DarkSlateBlue; background-color:LightGray;"><span class="caps">EX</span></strong>.</p>
<p>In summary, the Maxwell demon establishes an interesting relationship between thermodynamics and information, through the Landauer principles (which is itself a form of the second principle applied to the unit of information, the bit).<sup id="fnref:l"><a class="footnote-ref" href="#fn:l">3</a></sup></p>
<h1>Shannon entropy<sup id="fnref:s"><a class="footnote-ref" href="#fn:s">2</a></sup></h1>
<p>The basic model of information consists in an information <em>source</em>, a transmission <em>channel</em>, and destination <em>receiver</em>. These three components are build on a physical support. The source produces a <em>message</em> that is translated into a <em>signal</em> such that it can be sent using the channel to the receiver, which transforms the signal into the original message (perfect channel&nbsp;communication).</p>
<p>Consider a message as a sequence of events <span class="math">\(x\)</span> whose probability is <span class="math">\(p(x)\)</span>. For instance, the events can be a string of <span class="math">\(N\)</span> binary digits, or a sequence of letters in the set <span class="math">\(\{x_1, \ldots, x_K\}\)</span>, chosen from an alphabet of <span class="math">\(K\)</span> symbols. For the binary alphabet we have the probability distribution <span class="math">\(p(0) = p\)</span> and <span class="math">\(p(1) = 1-p\)</span>. A classical physical system with two distinguishable states can encode a <em>bit</em> of information. A bit is the elementary unit of&nbsp;information.</p>
<p>In the Shannon model, information is related to a set of messages emitted by a source, encoded using an alphabet whose letters <span class="math">\(x\)</span> are distributed according with some probability distribution <span class="math">\(p(x)\)</span>. A measure of the information might be the effective number of symbols needed to faithfully encode the message <span class="math">\(NH\)</span>, with <span class="math">\(N\)</span> is the number of events in the message. The optimal length per symbol <span class="math">\(H\)</span> is the Shannon entropy. We require the following properties to by satisfied by <span class="math">\(H\)</span>:</p>
<ul>
<li><span class="math">\(H\)</span> depends only on the probability <span class="math">\(p(x)\)</span>; </li>
<li><span class="math">\(H = H(p)\)</span> is a continuous&nbsp;function;</li>
<li>if the probability <span class="math">\(p\)</span> is uniform (for example <span class="math">\(p_k = 1/K,\, \forall k \in \{1, \ldots, K\}\)</span>), <span class="math">\(H\)</span> should be a monotonic increasing function of alphabet length (<span class="math">\(K\)</span>);</li>
<li><span class="math">\(H\)</span> is <em>additive</em>: if the choice of <span class="math">\(\{p_1,p_2,\ldots\}\)</span> can be subdivided into successive choices, then <span class="math">\(H\)</span> is the weighted sum of the individual values of <span class="math">\(H\)</span>; take for instance,
<div class="math">$$p = \{p_1, p_2, p_3\}$$</div>
    and
<div class="math">$$q = \{p_1, q_1, q_2, q_3 | q_1 = 1 - p_1, q_1q_2 = p_2, q_1q_3=p_3\}$$</div>
    then,
<div class="math">$$H(p) = H(p_1,q_1) + q_1 H(q_2,q_3)$$</div>
    (see the figure below for an&nbsp;example)</li>
</ul>
<blockquote>
<p><img src="/images/AQ-tree.svg" width="300"></p>
<p>The information measure of the two trees are equivalent, but with different distributions:
<div class="math">$$H(1/2,1/3,1/6) = H(1/2,1/2) + \frac{1}{2} H(2/3,1/3)$$</div>
Note that the sum of the arguments of <span class="math">\(H\)</span> is always&nbsp;1.</p>
</blockquote>
<p>This last property means that there exists a function <span class="math">\(I(p_n)\)</span> for fixed <span class="math">\(p_n\)</span>,&nbsp;satisfying,</p>
<ul>
<li><span class="math">\(I = I(p_n)\)</span> is continuous&nbsp;and,</li>
<li>it is additive <span class="math">\(I(p_n,p_m) = I(p_n) +&nbsp;I(p_m)\)</span></li>
<li>
<p>such&nbsp;that,</p>
<p>
<div class="math">$$H(p) = \braket{I} = \sum_n I(p_n) p_n\,.$$</div>
</p>
</li>
</ul>
<p>It is straightforward to demonstrate that <span class="math">\(I = -\text{const.} \log(p_n)\)</span> <strong style="color:DarkSlateBlue; background-color:LightGray;"><span class="caps">EX</span></strong>, and thus&nbsp;that
</p>
<div class="math">\begin{equation}
    H(p) = -\sum_n p_n \log p_n
    \label{e:Hp}
\end{equation}</div>
<p>
the Shannon <em>entropy</em>. The constant is determined by the condition <span class="math">\(\log 2 = 1\)</span>, which fixes the entropy of a bit to be one (in accordance with the definition of the information unit). Therefore, <span class="math">\(\log \cdot = \log_2 \cdot\)</span> stands for the base 2 logarithm (base <span class="math">\(\E\)</span> logarithm is denoted by <span class="math">\(\ln\)</span>).</p>
<p>The shannon entropy allows a rigorous definition of the unit of information: a bit corresponds to the entropy of a random variable taken two values with equal&nbsp;probability.</p>
<h3>Exercises</h3>
<ol>
<li>Demonstrate that <span class="math">\(H(pq) = H(p) + H(q)\)</span>.</li>
<li>Calculate and draw <span class="math">\(H(p)\)</span> for a bipartite system with distribution <span class="math">\(\{p, 1-p\}\)</span>.</li>
<li>Consider two random variables <span class="math">\(x\)</span> and <span class="math">\(y\)</span> whose joint distribution is <span class="math">\(p(x,y)\)</span>; show that:
<div class="math">$$H(p) \le H_x(p) + H_y(p)$$</div>
    where <span class="math">\(p(x) = \sum_y p(x,y)\)</span>, and
    <div class="math">$$H_x(p) = -\sum_{xy} p(x,y) \log p(x) = -\sum_x p(x) \log p(x),$$</div>
    and similar definitions for <span class="math">\(p(y)\)</span> and <span class="math">\(H_y\)</span>. You may use the fact that <span class="math">\(\log x \le (x-1)/ln 2\)</span>.</li>
<li>Define the conditional probabilities:
<div class="math">$$p(x|y) = \frac{p(x,y)}{p(y)},\; p(y|x) = \frac{p(x,y)}{p(x)}\,.$$</div>
    Show that
<div class="math">$$H(x,y) = H(x) + H(y|x) = H(y) + H(x | y)\,,$$</div>
    where we use the notation <span class="math">\(H(x) = H_x(p)\)</span>, <span class="math">\(H(y) = H_y(p)\)</span>, and the conditional entropy is defined by,
<div class="math">$$H(y | x) = -\sum_{xy} p(x,y) \log p(y | x),\; H(x | y) = - \sum_{xy} p(x,y) \log p(y)\,.$$</div>
   Deduce the inequality,
<div class="math">$$H(y) \ge H(y | x)\,.$$</div>
</li>
<li>
<p>A message is written in an alphabet of 4 characters <span class="math">\(\{a,b,c,d\}\)</span>, whose frequencies are
<div class="math">$$\{p(a) = 1/2, p(b) = 1/4, p(c) = 1/8, p(d) = 1/8\}$$</div>
    It is possible to code these four characters using two bits by
    <div class="math">$$\{00, 01, 10, 11\},$$</div>
    however this code is not optimal. Compute the length per character in bits of a typical message coded with
    <div class="math">$$\{0,10,110,111\},$$</div>
    in which we use fewer bits to code the liker characters (Answer: <span class="math">\(7/4\)</span>), and show that it corresponds to the Shannon entropy. Compare the result with the 2 bits&nbsp;code.</p>
<p>Find the messages coded by the string <span class="math">\(001001100010111\)</span>.</p>
</li>
</ol>
<h2>The Turing&nbsp;machine</h2>
<p>An algorithm can be defined as a series of instructions aiming at solving a given problem. A constructive way to mathematically specify an algorithm is through specific models of computation. A problem itself can be viewed as the computation of a general boolean function, a functions which takes and gives binary values <span class="math">\(f: \{0,1\}^{n} \rightarrow \{0,1\}^{m}\)</span> (in the case <span class="math">\(m=1\)</span> the algorithm solves questions that can be answered by yes or no). For instance, a universal set of gates provides a way to compute any boolean function (definition of universal); actually, the nand gate is universal: any other gate can be implemented by a convenient set of nand gates. The computation of <span class="math">\(f\)</span> can then be implemented by a circuit defined as a sequence of gates which transforms input bits into an output, the&nbsp;answer.</p>
<p>Another universal model of computation was devised by Turing in the form of a machine consisting in a tape and a read-write head, a set of internal states and a program. The thesis put forward by Turing (Church-Turing thesis) states&nbsp;that</p>
<blockquote>
<p>a Turing machine can solve any algorithmic problem, or equivalently, the class of Turing machine computable functions corresponds to the class of functions computable by means of&nbsp;algorithms.</p>
</blockquote>
<p>Elements of the Turing machine (figure&nbsp;below):</p>
<ol>
<li>A <em>tape</em> divided into cells numbered from 0 to infinity <span class="math">\(0, 1, 2, \ldots\)</span>, containing a finite number of letters from an alphabet <span class="math">\(a\)</span>, typically <span class="math">\(\{0,1\}\)</span> and a symbol for a blank cell <span class="math">\(b\)</span>, which can separate numeric cells, or fill the rest of the&nbsp;tape.</li>
<li>A <em>control unit</em>, which can be in any of a finite set of internal states <span class="math">\(s_1,s_2, \ldots, s_n\)</span>. In addition, there are two special states, the starting state <span class="math">\(s_0\)</span> and the halting state <span class="math">\(s_h\)</span>.</li>
<li>A head that can <em>read</em> the cell content and <em>write</em> a new character into it; the head can also move to the left (<span class="math">\(L\)</span>) or to the right (<span class="math">\(R\)</span>).</li>
<li>During the computation the internal state changes according to a series of statements or instructions called a <em>program</em>, which in addition control the motion of the head together with the read and write operations. Each instruction has the structure:
<div class="math">$$s, a, \bar{s}, \bar{a}, m$$</div>
    where <span class="math">\(s\)</span> is the actual state of the cell containing <span class="math">\(a \in \{0,1,b\}\)</span>, <span class="math">\(\bar{s}\)</span> is the new state of the cell, in which the head writes the new letter <span class="math">\(\bar{a}\)</span>, and <span class="math">\(m = L, R\)</span> is the motion of the head to the left or to the&nbsp;right.</li>
</ol>
<blockquote>
<p><img src="/images/AQ-turing_m.svg" alt="transition state diagram" style="width: 320px;"/></p>
<p>Turing machine: each cell of the tape contains a character from an alphabet, here the numers 0 and 1, and blank &#8220;b&#8221; (empty cell), the head read and writes characters according to the instructions of a program; as a result the internal state of the machine&nbsp;changes.</p>
</blockquote>
<p>A program instruction is then of the form <span class="math">\((s_1,a_1,s_2,a_2,m)\)</span> corresponding to the&nbsp;code</p>
<div class="highlight"><pre><span></span><code><span class="n">read</span><span class="p">(</span><span class="n">current_state</span><span class="p">,</span> <span class="n">current_letter</span><span class="p">)</span>
<span class="k">if</span> <span class="p">(</span><span class="n">current_state</span> <span class="o">==</span> <span class="n">s_1</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">current_letter</span> <span class="o">==</span> <span class="n">a_1</span><span class="p">):</span>
    <span class="n">new_state</span> <span class="o">=</span> <span class="n">s_2</span>
    <span class="n">write</span><span class="p">(</span><span class="n">a_2</span><span class="p">)</span>
    <span class="n">move</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</code></pre></div>

<p>where <span class="math">\(s_1\)</span> is the cell&#8217;s current state and <span class="math">\(a_1\)</span> the current letter of the alphabet <span class="math">\(a\)</span>; then the program changes the internal state to <span class="math">\(s_2\)</span> and writes the new value <span class="math">\(a_2\)</span> in the cell tape, finally it moves the head one step in the direction <span class="math">\(m\)</span>.</p>
<p>A set of such rules can be conveniently represented by a &#8220;transition diagram&#8221; in which a state is a labeled circle, and the transition between states are arrows labeled with the current and new letters, and the direction of the head motion (<span class="math">\(a_1,a_2,m\)</span> in the previous example). The transition graph contains all the information of the&nbsp;program.</p>
<p>An example of a program is given by the transition state diagram below. It solves the question: is the number of ones in a given binary string even or odd? It consists on two states <span class="math">\(s_1\)</span> which represents &#8220;even&#8221;, and <span class="math">\(s_2\)</span> which represents &#8220;odd&#8221;; the initial state is on the leftmost character and <span class="math">\(s_1\)</span>. Once the head reach a blank cell, it writes <span class="math">\(0\)</span> if the machine last state was <span class="math">\(s_1\)</span> (even), and <span class="math">\(1\)</span> if it was <span class="math">\(s_2\)</span> (odd). Reading the last cell we get the answer to the&nbsp;question.</p>
<blockquote>
<p><img src="/images/AQ-turing_tsd.svg" alt="transition state diagram" style="height: 200px;"/></p>
<p>This transition diagram describes a program to compute the parity of a binary string: if the number of 1 is odd it writes 1 and it writes 0 otherwise, at the end of the string. The initial state is <span class="math">\(s_1\)</span>, and the initial position is on the leftmost number. The arrows correspond to the program instructions, for instance <span class="math">\(1,0,R\)</span> means that the cell is in state 1, one writes 0 and move to <span class="math">\(R\)</span>.</p>
</blockquote>
<h3>Exercice</h3>
<p>Write the program corresponding to the previous transition&nbsp;diagram.</p>
<h2>Notes</h2>
<div class="footnote">
<hr>
<ol>
<li id="fn:Bennett">
<p>Bennett, &#8220;The thermodynamics of computatio,&#8221; Int. J. Theor. Phys. <strong>21</strong>, 905 (1982) (<a href="/pdfs/Bennett-1982fk.pdf">.pdf</a>)&#160;<a class="footnote-backref" href="#fnref:Bennett" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:s">
<p><span class="caps">C. E.</span> Shannon, <em>A mathematical theory of communication</em>, Bell syst, J., <strong>27</strong>, 379 (1948) <a href="/pdfs/shannon.pdf">.pdf</a>&#160;<a class="footnote-backref" href="#fnref:s" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:l">
<p>R. Landauer, <em>Information is physical</em>, Phys. Today <strong>44</strong>, 23 (1991) <a href="/pdfs/Landauer-1991.pdf">.pdf</a>&#160;<a class="footnote-backref" href="#fnref:l" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
</ol>
</div>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "true";

    if (true) {
        align = (screen.width < 700) ? "left" : align;
        indent = (screen.width < 700) ? "0em" : indent;
        linebreak = (screen.width < 700) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
  </div>
</article>
      </div>
    </div>

    <footer class="footer">
      <div class="container">
        <div class="row">
          <ul class="col-sm-6 list-inline">
            <li class="list-inline-item"><a href="/archives.html">Archives</a></li>
              <li class="list-inline-item"><a href="/tags.html">Tags</a></li>
            <li>&#xa9;Alberto&nbsp;Verga&nbsp;(2024)</li>
          </ul>
          <p class="col-sm-6 text-sm-right text-muted">
          <a href="https://github.com/getpelican/pelican" target="_blank">Pelican</a> / <a href="https://getbootstrap.com" target="_blank"><img alt="Bootstrap" src="/theme/css/bootstrap-solid.svg" style="height: 18px;"/></a> / <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons License Non-Commercial 4.0" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/88x31.png" /></a> CC 4.0
          </p>
        </div>
      </div>
    </footer>
  </body>

</html>